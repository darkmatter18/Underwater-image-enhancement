{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Underwater image enhancement model with PyTorch\n",
    "\n",
    "This notebook contains the `Custom Dataloader`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset HyperParams\n",
    "\n",
    "# Resize and crop\n",
    "preprocessT = 'resize_and_crop'\n",
    "\n",
    "# Image Load size\n",
    "load_sizeT = 286\n",
    "\n",
    "# Image Crop size\n",
    "crop_sizeT = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    IMG_EXTENSIONS = [\n",
    "        '.jpg', '.JPG', '.jpeg', '.JPEG',\n",
    "        '.png', '.PNG', '.ppm', '.PPM', '.bmp', '.BMP',\n",
    "        '.tif', '.TIF', '.tiff', '.TIFF',\n",
    "    ]\n",
    "\n",
    "    def __init__(self, dataroot, phase, max_dataset_size=float(\"inf\"), direction = \"AtoB\", input_nc = 3, output_nc = 3,\n",
    "                 serial_batches = True, preprocess= 'resize_and_crop', flip = True, load_size = 286, crop_size = 256):\n",
    "        \"\"\"\n",
    "        Custom Dataset for feeding Image to the network\n",
    "\n",
    "        :param dataroot: Root of the Dataset\n",
    "        :param phase: Folder phase for Dataset\n",
    "        :param max_dataset_size: Max size of the Dataset. Default: inf\n",
    "        :param direction: direction of the dataflow [\"AtoB\" | \"BtoA\" ]. Default: \"AtoB\"\n",
    "        :param input_nc: number of channels of input Image. Default: 3\n",
    "        :param output_nc: number of channels of output Image. Default: 3\n",
    "        :param serial_batches: Serial Batches for input. Default: 3\n",
    "        :param preprocess: Type of preprocessing applied. Default: \"resize_and_crop\"\n",
    "        :param flip: Is RandomHorizontalFlip is applied or not. Default: True\n",
    "        :param load_size: Size of the image on load. Default: 286\n",
    "        :param crop_size: Size of the image after resize. Default: 256\n",
    "        \"\"\"\n",
    "\n",
    "        self.dataroot = dataroot\n",
    "        self.phase = phase\n",
    "        self.max_dataset_size = max_dataset_size\n",
    "        self.direction = direction\n",
    "        self.input_nc = input_nc\n",
    "        self.output_nc = output_nc\n",
    "        self.serial_batches = serial_batches\n",
    "        self.preprocess = preprocess\n",
    "        self.flip = flip\n",
    "        self.load_size = load_size\n",
    "        self.crop_size = crop_size\n",
    "        \n",
    "        self.dir_A = os.path.join(self.dataroot, self.phase + 'A')  # create a path '/path/to/data/trainA'\n",
    "        self.dir_B = os.path.join(self.dataroot, self.phase + 'B')  # create a path '/path/to/data/trainB'\n",
    "\n",
    "        self.A_paths = sorted(self.make_dataset(self.dir_A, self.max_dataset_size))   # load images from '/path/to/data/trainA'\n",
    "        self.B_paths = sorted(self.make_dataset(self.dir_B, self.max_dataset_size))    # load images from '/path/to/data/trainB'\n",
    "        self.A_size = len(self.A_paths)  # get the size of dataset A\n",
    "        self.B_size = len(self.B_paths)  # get the size of dataset B\n",
    "        btoA = self.direction == 'BtoA'\n",
    "        input_nc = self.output_nc if btoA else self.input_nc       # get the number of channels of input image\n",
    "        output_nc = self.input_nc if btoA else self.output_nc      # get the number of channels of output image\n",
    "        self.transform_A = self.get_transform(grayscale=(input_nc == 1))\n",
    "        self.transform_B = self.get_transform(grayscale=(output_nc == 1))\n",
    "        \n",
    "    def get_params(self, size):\n",
    "        w, h = size\n",
    "        new_h = h\n",
    "        new_w = w\n",
    "        if self.preprocess == 'resize_and_crop':\n",
    "            new_h = new_w = self.load_size\n",
    "\n",
    "        x = random.randint(0, np.maximum(0, new_w - self.crop_size))\n",
    "        y = random.randint(0, np.maximum(0, new_h - self.crop_size))\n",
    "\n",
    "        flip = random.random() > 0.5\n",
    "\n",
    "        return {'crop_pos': (x, y), 'flip': flip}\n",
    "\n",
    "    def is_image_file(self, filename):\n",
    "        return any(filename.endswith(extension) for extension in self.IMG_EXTENSIONS)\n",
    "\n",
    "    def make_dataset(self, dataset_dir, max_dataset_size=float(\"inf\")):\n",
    "        images = []\n",
    "        assert os.path.isdir(dataset_dir), '%s is not a valid directory' % dir\n",
    "\n",
    "        for root, _, fnames in sorted(os.walk(dataset_dir)):\n",
    "            for fname in fnames:\n",
    "                if self.is_image_file(fname):\n",
    "                    path = os.path.join(root, fname)\n",
    "                    images.append(path)\n",
    "        return images[:min(max_dataset_size, len(images))]\n",
    "    \n",
    "    def get_transform(self, grayscale=False, convert=True):\n",
    "        transform_list = []\n",
    "        if grayscale:\n",
    "            transform_list.append(transforms.Grayscale(1))\n",
    "\n",
    "        if 'resize' in self.preprocess:\n",
    "            transform_list.append(transforms.Resize([self.load_size, self.load_size]))\n",
    "\n",
    "\n",
    "        if 'crop' in self.preprocess:\n",
    "            transform_list.append(transforms.RandomCrop(self.crop_size))\n",
    "\n",
    "        if not self.flip:\n",
    "            transform_list.append(transforms.RandomHorizontalFlip())\n",
    "\n",
    "        if convert:\n",
    "            transform_list += [transforms.ToTensor()]\n",
    "            if grayscale:\n",
    "                transform_list += [transforms.Normalize((0.5,), (0.5,))]\n",
    "            else:\n",
    "                transform_list += [transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "        return transforms.Compose(transform_list)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Return a data point and its metadata information.\n",
    "\n",
    "        :param index: a random integer for data indexing\n",
    "        :return: Returns a dictionary that contains A, B, A_paths and B_paths\n",
    "                    A (tensor)       -- an image in the input domain\n",
    "                    B (tensor)       -- its corresponding image in the target domain\n",
    "                    A_paths (str)    -- image paths\n",
    "                    B_paths (str)    -- image paths\n",
    "        \"\"\"\n",
    "\n",
    "        \n",
    "        a_path = self.A_paths[index % self.A_size]  # make sure index is within then range\n",
    "        if self.serial_batches:   # make sure index is within then range\n",
    "            index_b = index % self.B_size\n",
    "        else:   # randomize the index for domain B to avoid fixed pairs.\n",
    "            index_b = random.randint(0, self.B_size - 1)\n",
    "        b_path = self.B_paths[index_b]\n",
    "\n",
    "        # Open images\n",
    "        a_img = Image.open(a_path).convert('RGB')\n",
    "        b_img = Image.open(b_path).convert('RGB')\n",
    "\n",
    "        # apply image transformation\n",
    "        A = self.transform_A(a_img)\n",
    "        B = self.transform_B(b_img)\n",
    "\n",
    "        return {'A': A, 'B': B, 'A_paths': a_path, 'B_paths': b_path}\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        As we have two datasets with potentially different number of images,\n",
    "        we take a maximum of them.\n",
    "\n",
    "        :return: the total number of images in the dataset.\n",
    "        \"\"\"\n",
    "        \n",
    "        return max(self.A_size, self.B_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDatasetDataLoader():\n",
    "    \"\"\"Wrapper class of Dataset class that performs multi-threaded data loading\"\"\"\n",
    "\n",
    "    def __init__(self, dataset, batch_size=1, serial_batches=True, num_threads=2):\n",
    "        self.dataset = dataset\n",
    "        print(\"dataset [%s] was created\" % type(self.dataset).__name__)\n",
    "        self.dataloader = torch.utils.data.DataLoader(\n",
    "            self.dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=not serial_batches,\n",
    "            num_workers=int(num_threads))\n",
    "\n",
    "    def load_data(self):\n",
    "        return self\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the number of data in the dataset\"\"\"\n",
    "        return min(len(self.dataset), self.opt.max_dataset_size)\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"Return a batch of data\"\"\"\n",
    "        for i, data in enumerate(self.dataloader):\n",
    "            if i * self.opt.batch_size >= self.opt.max_dataset_size:\n",
    "                break\n",
    "            yield data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F:\\\\Projects\\\\Underwater-image-enhancement\\\\Dataset\\\\EUVP Dataset\\\\Paired\\\\underwater_dark'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(os.path.dirname(os.getcwd()), \"Dataset\", \"EUVP Dataset\", \"Paired\", \"underwater_dark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(os.path.join(os.path.dirname(os.getcwd()), \"Dataset\", \"EUVP Dataset\", \"Paired\", \"underwater_dark\"), \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset [CustomDataset] was created\n"
     ]
    }
   ],
   "source": [
    "dataloader = CustomDatasetDataLoader(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = iter(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('cv': conda)",
   "language": "python",
   "name": "python37464bitcvcondaec938c6715e24b838a7529a387064b5f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
