@misc{abadi2016tensorflow,
    title={TensorFlow: A system for large-scale machine learning},
    author={Martín Abadi and Paul Barham and Jianmin Chen and Zhifeng Chen and Andy Davis and Jeffrey Dean and Matthieu Devin and Sanjay Ghemawat and Geoffrey Irving and Michael Isard and Manjunath Kudlur and Josh Levenberg and Rajat Monga and Sherry Moore and Derek G. Murray and Benoit Steiner and Paul Tucker and Vijay Vasudevan and Pete Warden and Martin Wicke and Yuan Yu and Xiaoqiang Zheng},
    year={2016},
    eprint={1605.08695},
    archivePrefix={arXiv},
    primaryClass={cs.DC}
}

@misc{gopro,
    title={\url{https://gopro.com/}, 2016. Accessed: 3-15-2019},
    author={GoPro,  GoPro Hero 5}
}

@misc{blue-robotics,
    title={Low-light HD USB Camera. \url{https://www.bluerobotics.com/}, 2016. Accessed: 3-15-2019},
    author={BlueRobotics}
}

@misc{openrov,
    title={\url{https://www.openrov.com/}, 2017. Accessed: 3-15-2019},
    author={OpenROV. TRIDENT}
}

@article{uEye-cameras,
    author = {Dudek, Gregory and Giguère, Philippe and Prahacs, Chris and Saunderson, Shane and Sattar, Junaed and Torres-Méndez, L. Abril and Jenkin, Michael and German, Andrew and Hogue, Andrew and Ripsman, Arlene and Zacher, James and Milios, Evangelos and Liu, Hui and Zhang, Pifu and Buehler, Martin and Georgiades, Christina},
    year = {2007},
    month = {02},
    pages = {46 - 53},
    title = {AQUA: An amphibious autonomous robot},
    volume = {40},
    journal = {Computer},
    doi = {10.1109/MC.2007.6}
}

@misc{fabbri2018enhancing,
      title={Enhancing Underwater Imagery using Generative Adversarial Networks},
      author={Cameron Fabbri and Md Jahidul Islam and Junaed Sattar},
      year={2018},
      eprint={1801.04011},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{zhu2020unpaired,
      title={Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks},
      author={Jun-Yan Zhu and Taesung Park and Phillip Isola and Alexei A. Efros},
      year={2020},
      eprint={1703.10593},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@INPROCEEDINGS{5206848,
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Kai Li and Li Fei-Fei},
  booktitle={2009 IEEE Conference on Computer Vision and Pattern Recognition},
  title={ImageNet: A large-scale hierarchical image database},
  year={2009},
  volume={},
  number={},
  pages={248-255},
  doi={10.1109/CVPR.2009.5206848}
}

@misc{mirza2014conditional,
      title={Conditional Generative Adversarial Nets},
      author={Mehdi Mirza and Simon Osindero},
      year={2014},
      eprint={1411.1784},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{NIPS2014_5ca3e9b1,
 author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {Z. Ghahramani and M. Welling and C. Cortes and N. Lawrence and K. Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Generative Adversarial Nets},
 url = {https://proceedings.neurips.cc/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf},
 volume = {27},
 year = {2014}
}

@misc{goodfellow2017nips,
      title={NIPS 2016 Tutorial: Generative Adversarial Networks},
      author={Ian Goodfellow},
      year={2017},
      eprint={1701.00160},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@INPROCEEDINGS{6385685,
    author={Shkurti, Florian and Xu, Anqi and Meghjani, Malika and Gamboa Higuera, Juan Camilo and Girdhar, Yogesh and Giguère, Philippe and Dey, Bir Bikram and Li, Jimmy and Kalmbach, Arnold and Prahacs, Chris and Turgeon, Katrine and Rekleitis, Ioannis and Dudek, Gregory},
    booktitle={2012 IEEE/RSJ International Conference on Intelligent Robots and Systems},   title={Multi-domain monitoring of marine environments using a heterogeneous robot team},   year={2012},
    volume={},
    number={},
    pages={1747-1753},
    doi={10.1109/IROS.2012.6385685}
}

@article{Bingham2010RoboticTF,
  title={Robotic tools for deep water archaeology: Surveying an ancient shipwreck with an autonomous underwater vehicle},
  author={B. Bingham and B. Foley and H. Singh and R. Camilli and K. Delaporta and R. Eustice and A. Mallios and D. Mindell and C. Roman and D. Sakellariou},
  journal={J. Field Robotics},
  year={2010},
  volume={27},
  pages={702-717}
}

@article{https://doi.org/10.1002/rob.21837,
    author = {Islam, Md Jahidul and Ho, Marc and Sattar, Junaed},
    title = {Understanding human motion and gestures for underwater human–robot collaboration},
    journal = {Journal of Field Robotics},
    volume = {36},
    number = {5},
    pages = {851-873},
    doi = {https://doi.org/10.1002/rob.21837},
    url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/rob.21837},
    eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/rob.21837},
    abstract = {Abstract In this paper, we present a number of robust methodologies for an underwater robot to visually detect, follow, and interact with a diver for collaborative task execution. We design and develop two autonomous diver-following algorithms, the first of which utilizes both spatial- and frequency-domain features pertaining to human swimming patterns to visually track a diver. The second algorithm uses a convolutional neural network-based model for robust tracking-by-detection. In addition, we propose a hand gesture-based human–robot communication framework that is syntactically simpler and computationally more efficient than the existing grammar-based frameworks. In the proposed interaction framework, deep visual detectors are used to provide accurate hand gesture recognition; subsequently, a finite-state machine performs robust and efficient gesture-to-instruction mapping. The distinguishing feature of this framework is that it can be easily adopted by divers for communicating with underwater robots without using artificial markers or requiring memorization of complex language rules. Furthermore, we validate the performance and effectiveness of the proposed methodologies through a number of field experiments in closed- and open-water environments. Finally, we perform a user interaction study to demonstrate the usability benefits of our proposed interaction framework compared to the existing methods.},
    year = {2019}
}

@INPROCEEDINGS{lu2013underwaterimage,
  author={Lu, Huimin and Li, Yujie and Serikawa, Seiichi},
  booktitle={2013 IEEE International Conference on Image Processing},
  title={Underwater image enhancement using guided trigonometric bilateral filter and fast automatic color correction},
  year={2013},
  volume={},
  number={},
  pages={3412-3416},
  doi={10.1109/ICIP.2013.6738704}
}

@article{zhang2017underwaterimage,
    title = {Underwater image enhancement via extended multi-scale Retinex},
    journal = {Neurocomputing},
    volume = {245},
    pages = {1-9},
    year = {2017},
    issn = {0925-2312},
    doi = {https://doi.org/10.1016/j.neucom.2017.03.029},
    url = {https://www.sciencedirect.com/science/article/pii/S0925231217305246},
    author = {Shu Zhang and Ting Wang and Junyu Dong and Hui Yu},
    keywords = {Underwater image, Degradation, Enhancement, Color constancy, Multi-scale Retinex, Hybrid filter},
    abstract = {Underwater exploration has become an active research area over the past few decades. The image enhancement is one of the challenges for those computer vision based underwater researches because of the degradation of the images in the underwater environment. The scattering and absorption are the main causes in the underwater environment to make the images decrease their visibility, for example, blurry, low contrast, and reducing visual ranges. To tackle aforementioned problems, this paper presents a novel method for underwater image enhancement inspired by the Retinex framework, which simulates the human visual system. The term Retinex is created by the combinations of “Retina” and “Cortex”. The proposed method, namely LAB-MSR, is achieved by modifying the original Retinex algorithm. It utilizes the combination of the bilateral filter and trilateral filter on the three channels of the image in CIELAB color space according to the characteristics of each channel. With real world data, experiments are carried out to demonstrate both the degradation characteristics of the underwater images in different turbidities, and the competitive performance of the proposed method.}
}

@INPROCEEDINGS{8460552,
  author={Fabbri, Cameron and Islam, Md Jahidul and Sattar, Junaed},
  booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)},
  title={Enhancing Underwater Imagery Using Generative Adversarial Networks},
  year={2018},
  volume={},
  number={},
  pages={7159-7165},
  doi={10.1109/ICRA.2018.8460552}
}

@misc{isola2018imagetoimage,
      title={Image-to-Image Translation with Conditional Adversarial Networks},
      author={Phillip Isola and Jun-Yan Zhu and Tinghui Zhou and Alexei A. Efros},
      year={2018},
      eprint={1611.07004},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{eigen2015predicting,
      title={Predicting Depth, Surface Normals and Semantic Labels with a Common Multi-Scale Convolutional Architecture},
      author={David Eigen and Rob Fergus},
      year={2015},
      eprint={1411.4734},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{10.1145/383259.383295,
    author = {Hertzmann, Aaron and Jacobs, Charles E. and Oliver, Nuria and Curless, Brian and Salesin, David H.},
    title = {Image Analogies},
    year = {2001},
    isbn = {158113374X},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/383259.383295},
    doi = {10.1145/383259.383295},
    abstract = {This paper describes a new framework for processing images by example, called “image
    analogies.” The framework involves two stages: a design phase, in which a pair of
    images, with one image purported to be a “filtered” version of the other, is presented
    as “training data”; and an application phase, in which the learned filter is applied
    to some new target image in order to create an “analogous” filtered result. Image
    analogies are based on a simple multi-scale autoregression, inspired primarily by
    recent results in texture synthesis. By choosing different types of source image pairs
    as input, the framework supports a wide variety of “image filter” effects, including
    traditional image filters, such as blurring or embossing; improved texture synthesis,
    in which some textures are synthesized with higher quality than by previous approaches;
    super-resolution, in which a higher-resolution image is inferred from a low-resolution
    source; texture transfer, in which images are “texturized” with some arbitrary source
    texture; artistic filters, in which various drawing and painting styles are synthesized
    based on scanned real-world examples; and texture-by-numbers, in which realistic scenes,
    composed of a variety of textures, are created using a simple painting interface.},
    booktitle = {Proceedings of the 28th Annual Conference on Computer Graphics and Interactive Techniques},
    pages = {327–340},
    numpages = {14},
    keywords = {autoregression, non-photorealistic rendering, example-based rendering, Markov random fields, texture-by-numbers, texture synthesis, texture transfer},
    series = {SIGGRAPH '01}
}

@misc{johnson2016perceptual,
      title={Perceptual Losses for Real-Time Style Transfer and Super-Resolution},
      author={Justin Johnson and Alexandre Alahi and Li Fei-Fei},
      year={2016},
      eprint={1603.08155},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article {Laffont14,
    title = {Transient Attributes for High-Level Understanding and Editing of Outdoor Scenes},
    author = {Pierre-Yves Laffont and Zhile Ren and Xiaofeng Tao and Chao Qian and James Hays},
    journal = {ACM Transactions on Graphics (proceedings of SIGGRAPH)},
    volume = {33},
    number = {4},
    year = {2014}
}

@misc{long2015fully,
      title={Fully Convolutional Networks for Semantic Segmentation},
      author={Jonathan Long and Evan Shelhamer and Trevor Darrell},
      year={2015},
      eprint={1411.4038},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{shih2013data,
    author = {Shih, Yichang and Paris, Sylvain and Durand, Frédo and Freeman, William},
    year = {2013},
    month = {11},
    pages = {},
    title = {Data-driven Hallucination of Different Times of Day from a Single Outdoor Photo},
    volume = {32},
    journal = {ACM Transactions on Graphics (TOG)},
    doi = {10.1145/2508363.2508419}
}

@misc{wang2016generative,
      title={Generative Image Modeling using Style and Structure Adversarial Networks},
      author={Xiaolong Wang and Abhinav Gupta},
      year={2016},
      eprint={1603.05631},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{xie2015holisticallynested,
      title={Holistically-Nested Edge Detection},
      author={Saining Xie and Zhuowen Tu},
      year={2015},
      eprint={1504.06375},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{zhang2016colorful,
      title={Colorful Image Colorization},
      author={Richard Zhang and Phillip Isola and Alexei A. Efros},
      year={2016},
      eprint={1603.08511},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{ignatov2017dslrquality,
      title={DSLR-Quality Photos on Mobile Devices with Deep Convolutional Networks},
      author={Andrey Ignatov and Nikolay Kobyshev and Radu Timofte and Kenneth Vanhoey and Luc Van Gool},
      year={2017},
      eprint={1704.02470},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@INPROCEEDINGS{8578758,
    author={Chen, Yu-Sheng and Wang, Yu-Ching and Kao, Man-Hsin and Chuang, Yung-Yu},  booktitle={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},
    title={Deep Photo Enhancer: Unpaired Learning for Image Enhancement from Photographs with GANs}, year={2018},
    volume={},
    number={},
    pages={6306-6314},
    doi={10.1109/CVPR.2018.00660}
}

@INPROCEEDINGS{5596999,
    author={Horé, Alain and Ziou, Djemel},
    booktitle={2010 20th International Conference on Pattern Recognition},
    title={Image Quality Metrics: PSNR vs. SSIM},
    year={2010},
    volume={},
    number={},
    pages={2366-2369},
    doi={10.1109/ICPR.2010.579}
}

@ARTICLE{wang2004imagequalityassesment,
    author={Zhou Wang and Bovik, A.C. and Sheikh, H.R. and Simoncelli, E.P.},
    journal={IEEE Transactions on Image Processing},
    title={Image quality assessment: from error visibility to structural similarity},
    year={2004},
    volume={13},
    number={4},
    pages={600-612},
    doi={10.1109/TIP.2003.819861}
}

@article{10.1117/1.1636183,
    author = {Zia-ur Rahman and Daniel J. Jobson and Glenn A. Woodell},
    title = {{Retinex processing for automatic image enhancement}},
    volume = {13},
    journal = {Journal of Electronic Imaging},
    number = {1},
    publisher = {SPIE},
    pages = {100 -- 110},
    keywords = {Image processing, Visualization, Image enhancement, Information visualization, Image compression, Image visualization, Light sources and illumination, Digital imaging, Distortion, Reflectivity},
    year = {2004},
    doi = {10.1117/1.1636183},
    URL = {https://doi.org/10.1117/1.1636183}
}

@misc{berman2019underwater,
      title={Underwater Single Image Color Restoration Using Haze-Lines and a New Quantitative Dataset},
      author={Dana Berman and Deborah Levy and Shai Avidan and Tali Treibitz},
      year={2019},
      eprint={1811.01343},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@ARTICLE{5567108,
    author={He, Kaiming and Sun, Jian and Tang, Xiaoou},
    journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
    title={Single Image Haze Removal Using Dark Channel Prior},
    year={2011},
    volume={33},
    number={12},
    pages={2341-2353},
    doi={10.1109/TPAMI.2010.168}
}

@misc{cheng2016deep,
      title={Deep Colorization},
      author={Zezhou Cheng and Qingxiong Yang and Bin Sheng},
      year={2016},
      eprint={1605.00075},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@ARTICLE{7539399,
    author={Cai, Bolun and Xu, Xiangmin and Jia, Kui and Qing, Chunmei and Tao, Dacheng},
    journal={IEEE Transactions on Image Processing},
    title={DehazeNet: An End-to-End System for Single Image Haze Removal},
    year={2016},
    volume={25},
    number={11},
    pages={5187-5198},
    doi={10.1109/TIP.2016.2598681}
}

@misc{goodfellow2014generative,
      title={Generative Adversarial Networks},
      author={Ian J. Goodfellow and Jean Pouget-Abadie and Mehdi Mirza and Bing Xu and David Warde-Farley and Sherjil Ozair and Aaron Courville and Yoshua Bengio},
      year={2014},
      eprint={1406.2661},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@misc{arjovsky2017wasserstein,
      title={Wasserstein GAN},
      author={Martin Arjovsky and Soumith Chintala and Léon Bottou},
      year={2017},
      eprint={1701.07875},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@misc{zhao2017energybased,
      title={Energy-based Generative Adversarial Network},
      author={Junbo Zhao and Michael Mathieu and Yann LeCun},
      year={2017},
      eprint={1609.03126},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{mao2017squares,
      title={Least Squares Generative Adversarial Networks},
      author={Xudong Mao and Qing Li and Haoran Xie and Raymond Y. K. Lau and Zhen Wang and Stephen Paul Smolley},
      year={2017},
      eprint={1611.04076},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{yi2018dualgan,
      title={DualGAN: Unsupervised Dual Learning for Image-to-Image Translation},
      author={Zili Yi and Hao Zhang and Ping Tan and Minglun Gong},
      year={2018},
      eprint={1704.02510},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@ARTICLE{cho2018modelassisted,
  author={Cho, Younggun and Jeong, Jinyong and Kim, Ayoung},
  journal={IEEE Robotics and Automation Letters},
  title={Model-Assisted Multiband Fusion for Single Image Enhancement and Applications to Robot Vision},
  year={2018},
  volume={3},
  number={4},
  pages={2822-2829},
  doi={10.1109/LRA.2018.2843127}
}

@article{Berman2021UnderwaterSI,
  title={Underwater Single Image Color Restoration Using Haze-Lines and a New Quantitative Dataset},
  author={D. Berman and Deborah Levy and S. Avidan and T. Treibitz},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  year={2021}
}

@proceedings{kaufmann1992advances,
    title = {Advances in Neural Information Processing Systems 5, [NIPS     Conference]},
    year = {1992},
    isbn = {1558602747},
    publisher = {Morgan Kaufmann Publishers Inc.},
    address = {San Francisco, CA, USA}
}

@INPROCEEDINGS {maolih2017ieeeinternational,
    author = {X. Mao and Q. Li and H. Xie and R. K. Lau and Z. Wang and S. Smolley},
    booktitle = {2017 IEEE International Conference on Computer Vision (ICCV)},
    title = {Least Squares Generative Adversarial Networks},
    year = {2017},
    volume = {},
    issn = {2380-7504},
    pages = {2813-2821},
    keywords = {gallium nitride;generators;stability analysis;entropy;linear programming;image resolution},
    doi = {10.1109/ICCV.2017.304},
    url = {https://doi.ieeecomputersociety.org/10.1109/ICCV.2017.304},
    publisher = {IEEE Computer Society},
    address = {Los Alamitos, CA, USA},
    month = {oct}
}

{"mode":"full","isActive":false}

@inproceedings{shkurti2012multidomainmonitoring,
    title = {Multi-domain monitoring of marine environments using a heterogeneous robot team},
    type = {inproceedings},
    year = {2012},
    identifiers = {[object Object]},
    pages = {1747-1753},
    websites = {http://www.cim.mcgill.ca/~yogesh/publications/iros2012.pdf,http://ieeexplore.ieee.org/document/6385685/},
    month = {10},
    publisher = {IEEE},
    id = {63bbda11-1d94-3799-b7b8-42e14684ab37},
    created = {2012-07-05T20:52:54.000Z},
    file_attached = {true},
    profile_id = {2331788d-b144-3e67-ab8c-4abd7ab569c5},
    last_modified = {2018-01-26T05:04:18.495Z},
    read = {false},
    starred = {false},
    authored = {true},
    confirmed = {true},
    hidden = {false},
    citation_key = {Shkurti2012},
    folder_uuids = {9fe02bf3-6f9f-4e86-a6e6-c0190f2a6db9},
    private_publication = {false},
    bibtype = {inproceedings},
    author = {Shkurti, Florian and Xu, Anqi and Meghjani, Malika and Gamboa Higuera, Juan Camilo and Girdhar, Yogesh and Giguere, Philippe and Dey, Bir Bikram and Li, Jimmy and Kalmbach, Arnold and Prahacs, Chris and Turgeon, Katrine and Rekleitis, Ioannis and Dudek, Gregory},
    booktitle = {2012 IEEE/RSJ International Conference on Intelligent Robots and Systems}
}

@INPROCEEDINGS{chen2018unpairedlearning,
  author={Chen, Yu-Sheng and Wang, Yu-Ching and Kao, Man-Hsin and Chuang, Yung-Yu},
  booktitle={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  title={Deep Photo Enhancer: Unpaired Learning for Image Enhancement from Photographs with GANs},
  year={2018},
  volume={},
  number={},
  pages={6306-6314},
  doi={10.1109/CVPR.2018.00660}
}

@ARTICLE{dudek2007aquaanamphibious,
  author={Dudek, Gregory and Giguere, Philippe and Prahacs, Chris and Saunderson, Shane and Sattar, Junaed and Torres-Mendez, Luz-abril and Jenkin, Michael and German, Andrew and Hogue, Andrew and Ripsman, Arlene and Zacher, Jim and Milios, Evangelos and Liu, Hui and Zhang, Pifu and Buehler, Marti and Georgiades, Christina},
  journal={Computer},
  title={AQUA: An Amphibious Autonomous Robot},
  year={2007},
  volume={40},
  number={1},
  pages={46-53},
  doi={10.1109/MC.2007.6}}


  @misc{radford2016unsupervised,
      title={Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks},
      author={Alec Radford and Luke Metz and Soumith Chintala},
      year={2016},
      eprint={1511.06434},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{he2015deep,
      title={Deep Residual Learning for Image Recognition},
      author={Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
      year={2015},
      eprint={1512.03385},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{ulyanov2017instance,
      title={Instance Normalization: The Missing Ingredient for Fast Stylization},
      author={Dmitry Ulyanov and Andrea Vedaldi and Victor Lempitsky},
      year={2017},
      eprint={1607.08022},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{xu2015empirical,
      title={Empirical Evaluation of Rectified Activations in Convolutional Network},
      author={Bing Xu and Naiyan Wang and Tianqi Chen and Mu Li},
      year={2015},
      eprint={1505.00853},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@INPROCEEDINGS{6581545,
  author={Sartin, Maicon A. and da Silva, Alexandre C. R.},
  booktitle={2013 8th International Workshop on Reconfigurable and Communication-Centric Systems-on-Chip (ReCoSoC)},
  title={Approximation of hyperbolic tangent activation function using hybrid methods},
  year={2013},
  volume={},
  number={},
  pages={1-6},
  doi={10.1109/ReCoSoC.2013.6581545}}

@INPROCEEDINGS{8308186,
    author={Albawi, Saad and Mohammed, Tareq Abed and Al-Zawi, Saad},
    booktitle={2017 International Conference on Engineering and Technology (ICET)},
    title={Understanding of a convolutional neural network},
    year={2017},
    volume={},
    number={},
    pages={1-6},
    doi={10.1109/ICEngTechnol.2017.8308186}}

@misc{kingma2017adam,
    title={Adam: A Method for Stochastic Optimization},
    author={Diederik P. Kingma and Jimmy Ba},
    year={2017},
    eprint={1412.6980},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@article{bryson2015truecolor,
    author = {Bryson, Mitch and Johnson-Roberson, Matthew and Pizarro, Oscar and Williams, Stefan},
    year = {2015},
    month = {09},
    pages = {},
    title = {True Color Correction of Autonomous Underwater Vehicle Imagery},
    volume = {33},
    journal = {Journal of Field Robotics},
    doi = {10.1002/rob.21638}
}

@INPROCEEDINGS{akkaynak2018arevised,
    author={Akkaynak, Derya and Treibitz, Tali},
    booktitle={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},
    title={A Revised Underwater Image Formation Model},
    year={2018},
    volume={},
    number={},
    pages={6723-6732},
    doi={10.1109/CVPR.2018.00703}
}

@InProceedings{yu2019underwatergan,
    author="Yu, Xiaoli
    and Qu, Yanyun
    and Hong, Ming",
    editor="Zhang, Zhaoxiang
    and Suter, David
    and Tian, Yingli
    and Branzan Albu, Alexandra
    and Sid{\`e}re, Nicolas
    and Jair Escalante, Hugo",
    title="Underwater-GAN: Underwater Image Restoration via Conditional Generative Adversarial Network",
    booktitle="Pattern Recognition and Information Forensics",
    year="2019",
    publisher="Springer International Publishing",
    address="Cham",
    pages="66--75",
    abstract="Underwater image restoration is still a challenging task until now, because underwater images are degenerated due to the complex underwater imaging environment and poor light condition. The image degeneration includes color distortion, low contrast, and blur. In this paper, we propose Underwater-GAN, a conditional generative adversarial network for underwater image restoration. In Underwater-GAN, we use Wasserstein GAN with gradient penalty term as the backbone network. We design the loss function as the sum of the loss of generative adversarial network and the perceptual loss. In the discriminator of Underwater-GAN, we use a convolution patchGAN classifier to learn a structural loss instead of the image-level loss or pixel-wise loss. Moreover, we construct an underwater image dataset by simulating to generate underwater images according to the underwater imaging model. We train our model with these simulated underwater dataset. The results of our experiments show that the proposed method produces better visual qualitative and quantitative indicators than existing methods.",
    isbn="978-3-030-05792-3"
}



@article{li2017watergan,
    author = {Li, Jie and Skinner, Katherine and Eustice, Ryan and Johnson-Roberson, Matthew},
    year = {2017},
    month = {02},
    pages = {},
    title = {WaterGAN: Unsupervised Generative Network to Enable Real-time Color Correction of Monocular Underwater Images},
    volume = {PP},
    journal = {IEEE Robotics and Automation Letters},
    doi = {10.1109/LRA.2017.2730363}
}

@ARTICLE{liu2019underwaterimage,
      author={Liu, Peng and Wang, Guoyu and Qi, Hao and Zhang, Chufeng and Zheng, Haiyong and Yu, Zhibin},
      journal={IEEE Access},
      title={Underwater Image Enhancement With a Deep Residual Framework},
      year={2019},
      volume={7},
      number={},
      pages={94614-94629},
      doi={10.1109/ACCESS.2019.2928976}
    }

@ARTICLE{7305804,
  author={Panetta, Karen and Gao, Chen and Agaian, Sos},
  journal={IEEE Journal of Oceanic Engineering},
  title={Human-Visual-System-Inspired Underwater Image Quality Measures},
  year={2016},
  volume={41},
  number={3},
  pages={541-551},
  doi={10.1109/JOE.2015.2469915}}