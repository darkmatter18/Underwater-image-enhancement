{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'get_scheduler' from 'model.networks' (F:\\Projects\\Underwater-image-enhancement\\model\\networks.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-3b609e6073a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mitertools\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_pool\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImagePool\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnetworks\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbuild_D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuild_G\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_scheduler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGANLoss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'get_scheduler' from 'model.networks' (F:\\Projects\\Underwater-image-enhancement\\model\\networks.py)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import itertools\n",
    "from utils.image_pool import ImagePool\n",
    "from model.networks import build_D, build_G, get_scheduler, GANLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize network with normal\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NLayerDiscriminator(\n",
       "  (model): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_D() # Default values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize network with normal\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResnetGenerator(\n",
       "  (model): Sequential(\n",
       "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
       "    (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1), bias=False)\n",
       "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): ResnetBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): Dropout(p=0.5, inplace=False)\n",
       "        (5): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (11): ResnetBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): Dropout(p=0.5, inplace=False)\n",
       "        (5): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (12): ResnetBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): Dropout(p=0.5, inplace=False)\n",
       "        (5): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (13): ResnetBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): Dropout(p=0.5, inplace=False)\n",
       "        (5): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (14): ResnetBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): Dropout(p=0.5, inplace=False)\n",
       "        (5): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (15): ResnetBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): Dropout(p=0.5, inplace=False)\n",
       "        (5): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (16): ResnetBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): Dropout(p=0.5, inplace=False)\n",
       "        (5): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (17): ResnetBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): Dropout(p=0.5, inplace=False)\n",
       "        (5): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (18): ResnetBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): Dropout(p=0.5, inplace=False)\n",
       "        (5): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (19): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
       "    (20): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (21): ReLU(inplace=True)\n",
       "    (22): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
       "    (23): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (24): ReLU(inplace=True)\n",
       "    (25): ReflectionPad2d((3, 3, 3, 3))\n",
       "    (26): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
       "    (27): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_G() # Default values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycleGan:\n",
    "    def __init__(self, opt):\n",
    "        # Initialize the Models\n",
    "\n",
    "        # Global Variables\n",
    "        self.opt = opt\n",
    "        self.gpu_ids = opt.gpu_ids\n",
    "        self.isTrain = opt.isTrain\n",
    "        self.device = torch.device('cuda:{}'.format(self.gpu_ids[0])) if self.gpu_ids else torch.device('cpu')\n",
    "        self.metric = 0  # used for learning rate policy 'plateau'\n",
    "\n",
    "        self.G_AtoB = build_G(input_nc=opt.input_nc, output_nc=opt.output_nc, ngf=opt.ngf, norm=opt.norm,\n",
    "                              padding_type=opt.padding_type,\n",
    "                              use_dropout=not opt.no_dropout, n_blocks=opt.n_blocks, init_type=opt.init_type,\n",
    "                              init_gain=opt.init_gain, gpu_ids=opt.gpu_ids)\n",
    "\n",
    "        self.G_BtoA = build_G(input_nc=opt.output_nc, output_nc=opt.input_nc, ngf=opt.ngf, norm=opt.norm,\n",
    "                              padding_type=opt.padding_type,\n",
    "                              use_dropout=not opt.no_dropout, n_blocks=opt.n_blocks, init_type=opt.init_type,\n",
    "                              init_gain=opt.init_gain, gpu_ids=opt.gpu_ids)\n",
    "\n",
    "        if self.isTrain:\n",
    "            self.D_A = build_D(input_nc=opt.output_nc, ndf=opt.ndf, n_layers=opt.n_layers_D, norm=opt.norm,\n",
    "                               init_type=opt.init_type, init_gain=opt.init_gain, gpu_ids=opt.gpu_ids)\n",
    "            self.D_B = build_D(input_nc=opt.input_nc, ndf=opt.ndf, n_layers=opt.n_layers_D, norm=opt.norm,\n",
    "                               init_type=opt.init_type, init_gain=opt.init_gain, gpu_ids=opt.gpu_ids)\n",
    "\n",
    "            # only works when input and output images have the same number of channels\n",
    "            if opt.lambda_identity > 0.0:\n",
    "                assert (opt.input_nc == opt.output_nc)\n",
    "\n",
    "            # create image buffer to store previously generated images\n",
    "            self.fake_A_pool = ImagePool(opt.pool_size)\n",
    "            self.fake_B_pool = ImagePool(opt.pool_size)\n",
    "\n",
    "            # define loss functions\n",
    "            self.criterionGAN = GANLoss(opt.gan_mode).to(self.device)  # define GAN loss.\n",
    "            self.criterionCycle = torch.nn.L1Loss()\n",
    "            self.criterionIdt = torch.nn.L1Loss()\n",
    "\n",
    "            # initialize optimizers; schedulers will be automatically created by function <BaseModel.setup>.\n",
    "            self.optimizers = []\n",
    "            self.optimizer_G = torch.optim.Adam(itertools.chain(self.G_AtoB.parameters(), self.G_BtoA.parameters()),\n",
    "                                                lr=opt.lr, betas=(opt.beta1, 0.999))\n",
    "            self.optimizer_D = torch.optim.Adam(itertools.chain(self.D_A.parameters(), self.D_B.parameters()),\n",
    "                                                lr=opt.lr, betas=(opt.beta1, 0.999))\n",
    "            self.optimizers.append(self.optimizer_G)\n",
    "            self.optimizers.append(self.optimizer_D)\n",
    "\n",
    "            # lr Scheduler\n",
    "            self.schedulers = [get_scheduler(optimizer, lr_policy=opt.lr_policy, n_epochs=opt.n_epochs,\n",
    "                                             lr_decay_iters=opt.lr_decay_iters, epoch_count=opt.epoch_count,\n",
    "                                             n_epochs_decay=opt.n_epochs_decay) for optimizer in self.optimizers]\n",
    "\n",
    "    def update_learning_rate(self):\n",
    "        \"\"\"Update learning rates for all the networks; called at the end of every epoch\"\"\"\n",
    "        old_lr = self.optimizers[0].param_groups[0]['lr']\n",
    "        for scheduler in self.schedulers:\n",
    "            if self.opt.lr_policy == 'plateau':\n",
    "                scheduler.step(self.metric)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "\n",
    "        lr = self.optimizers[0].param_groups[0]['lr']\n",
    "        print('learning rate %.7f -> %.7f' % (old_lr, lr))\n",
    "\n",
    "    def eval(self):\n",
    "        \"\"\"Make models eval mode during test time\"\"\"\n",
    "        self.G_AtoB.eval()\n",
    "        self.G_BtoA.eval()\n",
    "\n",
    "        if self.isTrain:\n",
    "            self.D_A.eval()\n",
    "            self.D_B.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
